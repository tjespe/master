\section{Methodology}
\label{sec:methodology}

% Avsnitt om hva slags type review dette er og hvorfor vi har valgt den typen
To ensure reproducible and unbiased results, this review follows a structured methodology. \textcite{tranfield_et_al} note that traditional literature reviews often lack systematic rigor, making it challenging to determine the validity of their conclusions. To address this issue, each stage of the review was conducted systematically, guided by established literature review frameworks, particularly \textcite{snyder_2019} and \textcite{marzi_et_al_2024}. We adopt a structured systematic literature review (SLR) approach in line with \textcite{snyder_2019}, ensuring that the review is exhaustive and able to identify the most important research gaps. 

The review design and screening process followed the proposed steps by \textcite{marzi_et_al_2024}: (1) defining research questions and boundaries, (2) defining search queries, (3) selecting databases, (4) screening and cross-checking data and (5) cleaning and exporting data. This approach aligns with the design and conduct phases proposed by \textcite{snyder_2019}. Holistic and specific cluster thematic analysis was subsequently conducted as per \textcite{marzi_et_al_2024}, while bibliometric analysis following their (B-SLR) framework was also conducted, but excluded due to uninformative results. The cluster topic identification method for specific cluster thematic analysis suggested by \textcite{marzi_et_al_2024} was considered but not pursued, as the field was too small and fragmented for meaningful clusters to appear. Instead, a framework for breaking down the sample by the dimensions deemed important to answer the research questions was adopted. The exact process is outlined below, and reported according to \textcite{marzi_et_al_2024}'s guidelines.

% Avsnitt om databasevalg
\textbf{Database Selection}\nopagebreak

When doing a systematic review, it is important to conduct the search in a sufficient number of databases to ensure that all relevant papers are retrieved \parencite{hiebl_2021}. Furthermore, it is critical that the databases are relevant for the researched topic \parencite{marzi_et_al_2024}. To comprehensively capture relevant literature, this review utilized multiple well-established databases: SCOPUS, Web of Science, IEEE Xplore and ProQuest. SCOPUS and Web of Science were chosen due to their extensive coverage and comprehensive indexing of academic literature within a wide range of fields, as well as being the most extensively used databases for reviews \parencite{marzi_et_al_2024}. IEEE Xplore was included being a leading database for review papers in the fields of computer science and engineering \parencite{suhaimi2020systematic, carvalho2019systematic, cavacini2015best}, while ProQuest is another large academic database utilized in line with \textcite{gunnarsson2024}. All chosen databases allowed for advanced search queries without limitations on the number of clauses, in contrast to for example Google Scholar and ScienceDirect.

% Avsnitt om søkekriterier
\textbf{Search Strategy and Filtering Criteria}\nopagebreak

A comprehensive search and filtering strategy was developed to ensure the review covered all relevant literature. The search criteria were designed to ensure that as many papers relevant to the research questions as possible were included, as a narrow search query in this phase can lead to involuntary exclusion of relevant documents \parencite{marzi_et_al_2024,kuhrmann2017pragmatic, williams2021reexamining}. By requiring papers to match at least one term in four different clauses, the intention was to ensure that every paper was (1) within the field of AI, (2) about probabilistic modeling, (3) about forecasting, and (4) within finance. The keywords used are inspired by \textcite{Blasco_et_al_2024}, but we restructured the query to ensure that all articles meet each of the four criteria defining our scope, which is slightly broader. Table \ref{table:keywords_used} shows all keywords included within each clause. To minimize the risk of sample bias, the keywords were iteratively refined to ensure the topics deemed most relevant were covered. Conference papers, book chapters, editorials, and early access/unfinished papers were excluded to focus solely on peer-reviewed journal papers, which represent validated knowledge that has undergone peer review to ensure reliability \parencite{marzi_et_al_2024, hota2022hybrid}. Only English papers are included. The exact search queries are shown in Appendix \ref{appendix:search_queries}. 

\begin{table}[H]
    \centering
    \caption[Keywords Used in Database Search Queries]{Keywords used in database search queries across four key areas. Papers must match at least one term in each of the categories to be included in the initial sample.}
    \label{table:keywords_used}
    \begin{adjustbox}{width=0.5\textwidth,center}
    \begin{tabular}{p{0.15\textwidth}p{0.35\textwidth}}
        \toprule
        \textbf{Category} & \textbf{Keywords\tablefootnote{The asterisk (*) is a wildcard character.}} \\
        \midrule
        (1) Artificial Intelligence (AI) & \texttt{AI, ML, Artificial intelligence, Machine learning, Deep learning, Reinforcement learning, Supervised learning} \\
        \addlinespace
        (2) Probabilistic Modeling & \texttt{Probabilistic, Uncertainty quantification, Prediction interval*, Confidence interval*, Distributional forecast, Bayesian, Gaussian process, Undirected graphical model*, Markov Network*, Markov random field*, Probabilistic Graphical Model*, Variational inference, Monte Carlo dropout, Hidden Markov model*, Gaussian mixture model*, Variational Autoencoder*, Dirichlet Process} \\
        \addlinespace
        \text{(3) Forecasting} & \texttt{Forecast*, Predict*, Estimat*} \\
        \addlinespace
        \text{(4) Finance} & \texttt{Foreign exchange, Forex, Equity market*, Stock price*, Stock market*, Stock return*, Stock trend*, Stock index, Stock indices, Commodities, Value-at-risk, Value at risk, CVaR, Expected shortfall, Financial time series,  Implied volatility, Realized volatility, Cryptocurrency, Bitcoin, (Volatility AND Financ*)} \\
        \bottomrule
    \end{tabular}
    \end{adjustbox}
\end{table}

The search was conducted across all the databases in October 15, 2024, yielding a combined initial search result of 570 papers (see Figure \ref{fig:search_sample_by_database}). The search results were then merged, and duplicates were removed, resulting in 340 unique papers. 

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{Images/search_sample_by_database.png}
    \caption[Number of papers per database from search]{Number of papers per database resulting from search.}
    \label{fig:search_sample_by_database}
\end{figure}



% Avsnitt om screening
\textbf{Inclusion Criteria}\nopagebreak

Following the definition of the search strategy, inclusion criteria for the screening process was constructed. Three main criteria were defined for the first screening phase:

\begin{enumerate}
    \item The paper must discuss a model that predicts the price of some financial instrument, e.g. a stock, an option, an index, etc.
    \item The model must be an AI or machine learning model, i.e. more complicated than traditional statistical or econometric models
    \item The model must be able to provide more than a point prediction, i.e. it includes either variance, a distribution or some other financial risk measure such as VaR
\end{enumerate}

Furthermore, some explicit rules in cases of doubt in the aforementioned three was constructed:
\begin{itemize}
    \item Studies must demonstrate practical implementation of the proposed models, not merely discuss theoretical frameworks
    \item To distinguish between traditional statistical models and machine learning models, we classified models as machine learning if they demonstrated complexity beyond Bayesian Structural Time-Series and required machine learning estimation techniques, such as gradient descent
    \item Unlike \textcite{Blasco_et_al_2024}, we excluded models that use probabilistic components solely for purposes such as regularization (e.g., most Bayesian Regularized Neural Networks and Neural Networks with dropout during training), optimization, or feature extraction. As \textcite{Blasco_et_al_2024} observed, these papers rarely quantify uncertainty
    \item MLPs/FFNNs with Gaussian activation functions were excluded, as they do not provide probabilistic estimates
    \item Classification models were only included if they are based on probability theory, such as Bayesian Networks, PNNs and HMMs
    \item Papers focusing on commodities were included only if they predicted futures prices or returns, except for gold and oil, which closely resemble financial time series and correlate with financial variables \parencite{Gokmenoglu2015}
\end{itemize}
These became especially relevant during screening Phase 2, when full-text screening was conducted. 

\textbf{Screening Phase 1: Initial Screening}\nopagebreak

After obtaining the initial set of unique papers, consisting of 340 paper, Phase 1 of the screening process started. In this stage, the purpose was to remove papers irrelevant to the research questions to be addressed in the review.

To make the screening process more efficient, a large language model (``o1-mini'' from OpenAI) was given the title and abstract of each paper and tasked with generating a short summary and assessing compliance with each criteria. Subsequently, the results from the language model, along with the title, abstract and a link to the full paper was given to one of the researchers to make a decision on whether to include or exclude each paper. Through this process, we were able to quickly make decisions on obvious cases, and conduct a more thorough assessment where we potentially could open and skim through the paper in cases of doubt. This enabled a large number of papers to be screened in a short amount of time, and thorough assessments that were not based solely on title and abstract. The exact process is outlined in Appendix \ref{appendix:screening_process_with_ai} and the code used is published at \href{https://github.com/tjespe/literature-review/}{Github}\footnote{\label{footnote:github_link}\href{https://github.com/tjespe/literature-review/}{https://github.com/tjespe/literature-review/}}. Through this process, the number of papers in the sample was reduced from 340 to 138. 



% Avsnitt om den initielle analysen (taggingen)
\textbf{Screening Phase 2: Full-text screening, Data extraction and Analysis}\nopagebreak

Following the initial screening and dataset extraction, a second, more comprehensive screening was conducted, involving full-text review and thorough evaluation of each paper. Data was extracted on key information, such as the type of probabilistic model used, any hybrid model integrations, target variable, type of uncertainty addressed, metrics used for assessing uncertainty estimates, how the model compared to benchmarks etc. Each article was tagged and categorized based on these variables which were summarized in a structured format for subsequent analysis. 

In this detailed evaluation a deeper understanding of each paper and its model implementation was achieved, leading to the exclusion of several papers not passing the aforementioned criteria after all. These exclusions were not identifiable during the initial screening, mostly due to the difficulty of fully understanding the model implementation details before reading full-text. Typical exclusions in this phase was: the model could not be considered AI or ML after all, the model architecture was only discussed and not actually implemented, the model did not have the ability to produce probabilistic outputs, or it was a classification model not based on probability theory. Therefore, the final sample size of included papers presented in this review is \samplesize. A descriptive table summarizing key attributes for the included papers has been compiled and is available in Appendix \ref{appendix:descriptive_table_of_all_articles}. Figure \ref{fig:screening_and_cleaning_funnel} illustrates how the sample size was reduced down through the cleaning and screening.

  \begin{figure*}[h]
      \centering
      \includegraphics[width=1\linewidth]{Images/screening_funnel.png}
      \caption[Flow chart illustrating the sample size throughout cleaning and screening phases]{Flow chart illustrating the reduction in sample size throughout cleaning and screening phases.}
      \label{fig:screening_and_cleaning_funnel}
  \end{figure*}

% Avsnitt om hvordan deskriptiv statistikk ble laget og hvorfor, inkl. analysen som viste at de sjeldent referer til hverandre, med referanse til den B-SLR-artikkelen
\textbf{Descriptive Statistics and Analysis}\nopagebreak

Descriptive statistics and analysis were generated using a Python Jupyter Notebook for the final sample of papers. Pandas was used for data manipulation and categorization, and Matplotlib for data visualizations and plotting. All code used for the analysis is disclosed and available for reproducibility at \href{https://github.com/tjespe/literature-review/}{Github}\textsuperscript{\ref{footnote:github_link}}.

% Avsnitt om den videre analysen (altså breakdown by model, by target variable, etc.): hvorfor og hvordan har vi gjort det?
\textbf{Approach for Further Analysis}\nopagebreak

The further analysis of the papers follows a structured breakdown along several dimensions: type of model, model output, asset class and type of uncertainty. Each section will provide insights that inform the research questions before concrete conclusions are presented for each question in Section \ref{sec:discussion}. The dimensions used to analyze the sample align with those commonly employed in similar reviews, providing a structured framework to effectively assess the current state of research \parencite{Blasco_et_al_2024}.

